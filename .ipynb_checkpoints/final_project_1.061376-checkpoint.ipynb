{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "import gc\n",
    "import random as python_random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras seeding to produce reproduciable results\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into variable\n",
    "\n",
    "train = pd.read_csv('./final_project_data/sales_train.csv')\n",
    "items = pd.read_csv('./final_project_data/items.csv')\n",
    "item_categories = pd.read_csv('./final_project_data/item_categories.csv')\n",
    "shops = pd.read_csv('./final_project_data/shops.csv')\n",
    "test = pd.read_csv('./final_project_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of data are:\n",
      " train:(2935849, 6)\n",
      " test:(214200, 3)\n",
      " items:(22170, 3)\n",
      " item_categories:(84, 2) \n",
      " shops:(60, 2)\n",
      "unique shops in test:42, unique item in test:5100 possible combinations:214200which is same as the number of rows:214200\n"
     ]
    }
   ],
   "source": [
    "print(f'Shapes of data are:\\n train:{train.shape}\\n test:{test.shape}\\n items:{items.shape}' +\n",
    "     f'\\n item_categories:{item_categories.shape} \\n shops:{shops.shape}')\n",
    "\n",
    "print(f'unique shops in test:{test.shop_id.nunique()}, unique item in test:{test.item_id.nunique()}' +\n",
    "     f' possible combinations:{test.shop_id.nunique() * test.item_id.nunique()}' +\n",
    "     f'which is same as the number of rows:{test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'date_block_num', 'shop_id', 'item_id', 'item_price',\n",
      "       'item_cnt_day'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'shop_id', 'item_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " before duplicate drop:(214200, 3)  after duplicate drop:(214200, 3)\n"
     ]
    }
   ],
   "source": [
    "# Copy the original dataset to temp \n",
    "sales = train.copy()\n",
    "sales_test = test.copy()\n",
    "\n",
    "sales_index = sales_test['ID']\n",
    "sales_test.drop_duplicates()\n",
    "print(f' before duplicate drop:{test.shape}  after duplicate drop:{sales_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_33 = sales.loc[sales['date_block_num'] == 33]\n",
    "item_sales_last_month = sales_33.groupby(['shop_id','item_id'])['item_cnt_day'].sum().reset_index()\n",
    "item_price_last_month = sales_33.groupby(['shop_id','item_id'])['item_price'].mean().reset_index()\n",
    "# sales_last_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_test['date_block_num'] = 34\n",
    "sales_test = sales_test.merge(item_sales_last_month, on=['shop_id', 'item_id'], how='left').fillna(0)\n",
    "sales_test = sales_test.merge(item_price_last_month, on=['shop_id', 'item_id'], how='left').fillna(0)\n",
    "sales_test.drop('ID', axis=1, inplace=True)\n",
    "# sales_test.head()\n",
    "sales_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2935849, 6)\n",
      "(3150049, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3150044</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>18454</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150045</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>16188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150046</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>15757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150047</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>19648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150048</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "3150044  NaN              34       45    18454        99.0           1.0\n",
       "3150045  NaN              34       45    16188         0.0           0.0\n",
       "3150046  NaN              34       45    15757         0.0           0.0\n",
       "3150047  NaN              34       45    19648         0.0           0.0\n",
       "3150048  NaN              34       45      969         0.0           0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sales.shape)\n",
    "sales = sales.append(sales_test, ignore_index=True, sort=False)\n",
    "print(sales.shape)\n",
    "sales.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a feature matrix\n",
    "\n",
    "* itertools.product(*iterables):\n",
    "\n",
    "It returns the cartesian product of all the itrable provided as the argument. For example, product(arr1, arr2, arr3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "    # Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby data to get shop-item-month aggregates\n",
    "# Rename the aggregate column to target\n",
    "gb = (sales.groupby(index_cols,as_index=False)['item_cnt_day']\n",
    "          .sum()\n",
    "          .rename(columns = {'item_cnt_day':'target'}))\n",
    "\n",
    "# Join it to the grid\n",
    "# grid is formed by all combination of unique shop,ite,month hence is many more rows,\n",
    "# Joining grid with gb will result in the target column of gb having NaNs\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but with shop-month aggregates\n",
    "gb = (sales.groupby(['shop_id', 'date_block_num'],as_index=False)['item_cnt_day']\n",
    "          .sum()\n",
    "          .rename(columns = {'item_cnt_day':'target_shop'}))\n",
    "\n",
    "#gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but with item-month aggregates\n",
    "gb = (sales.groupby(['item_id', 'date_block_num'],as_index=False)['item_cnt_day']\n",
    "          .sum().rename(columns = {'item_cnt_day':'target_item'}))\n",
    "\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "#all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mean Price for each item\n",
    "# gb = sales.groupby(index_cols,as_index=False)['item_price'].mean().rename(\n",
    "#                                                                     columns = {'item_price':'target_price'})\n",
    "\n",
    "# all_data = pd.merge(all_data, gb, how='left', on=index_cols).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128050, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag feature\n",
    "\n",
    "After creating a grid, we can calculate some features. We will use lags from [1, 2, 3, 4, 5, 12] months ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns that we will use to create lags\n",
    "# These columns are the target column which we created above by groupby\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
    "# print(index_cols)\n",
    "# print(cols_to_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target', 'target_item', 'target_shop']\n"
     ]
    }
   ],
   "source": [
    "print(cols_to_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:41<00:00, 10.30s/it]\n"
     ]
    }
   ],
   "source": [
    "# Months choosen for lag\n",
    "shift_range = [1, 2, 11,12]\n",
    "\n",
    "for month_shift in tqdm(shift_range):\n",
    "    # Create a temp df\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    # Shift Month column value\n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    # we will get a df with date_block_num column updated to the shift and \n",
    "    # and all target column names reflecting the month shift data\n",
    "    # corresponding to the date_block_num value i.e\n",
    "    # if date_block_num is 'N' the target_lag_M is the target_lag data from \n",
    "    # month N-M !!!! Superb bit of code.\n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    # Iteratively add all the lagging months\n",
    "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "\n",
    "del train_shift\n",
    "\n",
    "# all_data.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_shop', 'target_item', 'target', 'date_block_num']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num'] >= 12] \n",
    "\n",
    "# List of all lagged features\n",
    "# Iterate for col name and check the last character occurs in the lag month list\n",
    "#fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "items = ''\n",
    "for item in shift_range:\n",
    "    items = items + str(item)\n",
    "\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in items]\n",
    "\n",
    "# We will drop these at fitting stage\n",
    "# Drop the original target columns and the date_block_num\n",
    "# essentially keeping the fit_cols and every index col except one\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "\n",
    "to_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_drop_cols.remove('target_shop')\n",
    "# to_drop_cols.remove('target_item')\n",
    "\n",
    "# to_drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Category for each item\n",
    "# item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "# all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "\n",
    "# Mean Price for each item\n",
    "gb = sales.groupby(index_cols,as_index=False)['item_price'].mean()\n",
    "\n",
    "all_data = pd.merge(all_data, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# gb = sales.groupby(index_cols,as_index=False)['item_price'].max().rename(\n",
    "#                                                                 columns = {'item_price':'item_price_max'})\n",
    "\n",
    "# all_data = pd.merge(all_data, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# gb = sales.groupby(index_cols,as_index=False)['item_price'].min().rename(\n",
    "#                                                                 columns = {'item_price':'item_price_min'})\n",
    "\n",
    "# all_data = pd.merge(all_data, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# all_data['revenue'] = all_data['target'] * all_data['item_price']\n",
    "\n",
    "\n",
    "all_data = downcast_dtypes(all_data)\n",
    "\n",
    "del gb\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions = all_data['shop_id'].astype('str') + '_' + all_data['item_id'].astype('str')\n",
    "\n",
    "# label_enc = LabelEncoder()\n",
    "# all_data = all_data.assign(shop_item=label_enc.fit_transform(interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.drop('shop_item', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this end, we've created a feature matrix. It is stored in ```all_data variable```. Take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "      <th>target_shop</th>\n",
       "      <th>target_item</th>\n",
       "      <th>target_lag_1</th>\n",
       "      <th>target_item_lag_1</th>\n",
       "      <th>target_shop_lag_1</th>\n",
       "      <th>target_lag_2</th>\n",
       "      <th>target_item_lag_2</th>\n",
       "      <th>target_shop_lag_2</th>\n",
       "      <th>target_lag_11</th>\n",
       "      <th>target_item_lag_11</th>\n",
       "      <th>target_shop_lag_11</th>\n",
       "      <th>target_lag_12</th>\n",
       "      <th>target_item_lag_12</th>\n",
       "      <th>target_shop_lag_12</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6639289</th>\n",
       "      <td>45</td>\n",
       "      <td>18454</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639290</th>\n",
       "      <td>45</td>\n",
       "      <td>16188</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639291</th>\n",
       "      <td>45</td>\n",
       "      <td>15757</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639292</th>\n",
       "      <td>45</td>\n",
       "      <td>19648</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639293</th>\n",
       "      <td>45</td>\n",
       "      <td>969</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n",
       "6639289       45    18454              34     1.0        683.0          2.0   \n",
       "6639290       45    16188              34     0.0        683.0          1.0   \n",
       "6639291       45    15757              34     0.0        683.0          5.0   \n",
       "6639292       45    19648              34     0.0        683.0          2.0   \n",
       "6639293       45      969              34     0.0        683.0          3.0   \n",
       "\n",
       "         target_lag_1  target_item_lag_1  target_shop_lag_1  target_lag_2  \\\n",
       "6639289           1.0                2.0              702.0           0.0   \n",
       "6639290           0.0                1.0              702.0           0.0   \n",
       "6639291           0.0                5.0              702.0           0.0   \n",
       "6639292           0.0                2.0              702.0           0.0   \n",
       "6639293           0.0                3.0              702.0           0.0   \n",
       "\n",
       "         target_item_lag_2  target_shop_lag_2  target_lag_11  \\\n",
       "6639289                1.0              654.0            4.0   \n",
       "6639290                3.0              654.0            0.0   \n",
       "6639291                3.0              654.0            0.0   \n",
       "6639292                3.0              654.0            0.0   \n",
       "6639293                5.0              654.0            0.0   \n",
       "\n",
       "         target_item_lag_11  target_shop_lag_11  target_lag_12  \\\n",
       "6639289               106.0              1551.0            0.0   \n",
       "6639290                 0.0                 0.0            0.0   \n",
       "6639291                16.0              1551.0            0.0   \n",
       "6639292                11.0              1551.0            0.0   \n",
       "6639293                 7.0              1551.0            0.0   \n",
       "\n",
       "         target_item_lag_12  target_shop_lag_12  item_price  \n",
       "6639289                 0.0                 0.0        99.0  \n",
       "6639290                 0.0                 0.0         0.0  \n",
       "6639291                 9.0              1251.0         0.0  \n",
       "6639292                 0.0                 0.0         0.0  \n",
       "6639293                 6.0              1251.0         0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/ validation/test split\n",
    "\n",
    "34th month data is the test set. 32nd and 33rd data will be taken as validation split and rest as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = all_data['date_block_num']\n",
    "\n",
    "\n",
    "X_train = all_data.loc[(dates <  32)].drop(to_drop_cols, axis=1)\n",
    "X_val = all_data.loc[(dates ==  33) | (dates ==  32)].drop(to_drop_cols, axis=1)\n",
    "X_test =  all_data.loc[dates == 34].drop(to_drop_cols, axis=1)\n",
    "\n",
    "y_train = all_data.loc[(dates <  32), 'target'].values\n",
    "y_val =  all_data.loc[((dates ==  33) | (dates ==  32)), 'target'].values\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu',input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "       layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "    #optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0)\n",
    "    optimizer='rmsprop'\n",
    "    \n",
    "    model.compile(loss=root_mean_squared_error,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mse',])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14318/59683 [======>.......................] - ETA: 1:06 - loss: 3.0767 - mse: 436.8510"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "history = keras_model.fit(\n",
    "  X_train, y_train,\n",
    "  epochs=EPOCHS,\n",
    "    batch_size=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    #callbacks=[callbacks],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.ylim(bottom=10, top=12)\n",
    "# plt.xlim(left=1100, right = 1200)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of test data, fit model\n",
    "preds_test = keras_model.predict(X_test)\n",
    "\n",
    "# The prediction is of type numpy.ndarray\n",
    "preds_list = preds_test.tolist()\n",
    "\n",
    "# Extract the prediction and put it in a list\n",
    "prediction = []\n",
    "for item in preds_list:\n",
    "    prediction.append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\n",
    "# xgb_model.fit(X_train, y_train, \n",
    "#              early_stopping_rounds=5, \n",
    "#              eval_set=[(X_val, y_val)], \n",
    "#              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = xgb_model.predict(df_ts_expand)\n",
    "# prediction = (np.clip(preds, 0, 20)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.clip(prediction, 0, 20)\n",
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'ID': sales_index,\n",
    "                       'item_cnt_month': prediction})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_csv('XbgModel.csv', index=False)\n",
    "output.to_csv('KerasModel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
