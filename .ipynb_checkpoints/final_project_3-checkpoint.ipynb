{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "import gc\n",
    "import random as python_random\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras seeding to produce reproduciable results\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "\n",
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64` and `int32` to `int16`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype in [\"int32\", \"int64\"]]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int16)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def lag_feature(df, lags, col):\n",
    "    tmp = df[['date_block_num','shop_id','item_id',col]]\n",
    "    for i in tqdm(lags):\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left').fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into variable\n",
    "\n",
    "train = pd.read_csv('./final_project_data/sales_train.csv')\n",
    "items = pd.read_csv('./final_project_data/items.csv')\n",
    "category = pd.read_csv('./final_project_data/item_categories.csv')\n",
    "shops = pd.read_csv('./final_project_data/shops.csv')\n",
    "test = pd.read_csv('./final_project_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = downcast_dtypes(train)\n",
    "sales = train.copy()\n",
    "#sales_train = train.copy() \n",
    "sales_test = test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove outliers\n",
    "\n",
    "# sales_train = sales_train[(sales_train.item_price<100000) & (sales_train.item_cnt_day<1001)]\n",
    "# sales_train.loc[sales_train.item_price<0, 'item_price'] = 0\n",
    "\n",
    "# sales_train.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_name           ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D\n",
       "item_id                                                     0\n",
       "item_category_id                                           40\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_category_name    PC - Гарнитуры/Наушники\n",
       "item_category_id                            0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shop_name    !Якутск Орджоникидзе, 56 фран\n",
       "shop_id                                  0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shops.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <td>5037</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1\n",
       "ID          0     1\n",
       "shop_id     5     5\n",
       "item_id  5037  5320"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_test.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Items in train:21807\t Items in test: 5100\n",
      " Shops in train:60\t Shops in test: 42\n",
      "0\n",
      "363\n"
     ]
    }
   ],
   "source": [
    "print(f' Items in train:{sales.item_id.nunique()}\\t Items in test: {sales_test.item_id.nunique()}')\n",
    "print(f' Shops in train:{sales.shop_id.nunique()}\\t Shops in test: {sales_test.shop_id.nunique()}')\n",
    "\n",
    "# Shops in test not in train\n",
    "print(len(np.setdiff1d(sales_test.shop_id.unique(),sales.shop_id.unique())))\n",
    "\n",
    "# Items in test not in train\n",
    "print(len(np.setdiff1d(sales_test.item_id.unique(),sales.item_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Sale figures for each item\n",
    "\n",
    "# sales_item_id = (sales_train.groupby(['date_block_num', 'item_id'],as_index=False)['item_cnt_day']\n",
    "#                   .sum().rename(columns = {'item_cnt_day':'item_cnt_month'}))\n",
    "\n",
    "# # Items with zero sales in last 6 months\n",
    "# sold_items = sales_item_id.loc[(sales_item_id.date_block_num > 26\n",
    "#                                ) & (sales_item_id.item_cnt_month > 0)].item_id.unique()\n",
    "# no_sales = sales_train.item_id.nunique() - len(sold_items)\n",
    "\n",
    "# print(f'Items with no sales in last 6 months in train: {no_sales}')\n",
    "# print(f'Items with no sales in last 6 months in test: ' +\n",
    "#        f'{len(np.setdiff1d(sales_test.item_id.unique(),sold_items))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sale figures for each shop\n",
    "# sales_shop_id = (sales_train.groupby(['date_block_num', 'shop_id'],as_index=False)['item_cnt_day']\n",
    "#                   .sum().rename(columns = {'item_cnt_day':'item_cnt_month'}))\n",
    "\n",
    "# # Items with zero sales in last 6 months\n",
    "# sold_shops = sales_shop_id.loc[(sales_shop_id.date_block_num > 26\n",
    "#                                ) & (sales_shop_id.item_cnt_month > 0)].shop_id.unique()\n",
    "# no_sales = sales_train.shop_id.nunique() - len(sold_shops)\n",
    "\n",
    "# print(f'Shops with no sales in last 6 months in train: {no_sales}')\n",
    "# print(f'Shops with no sales in last 6 months in test: ' +\n",
    "#        f'{len(np.setdiff1d(sales_test.shop_id.unique(),sold_shops))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare test data for appending to train\n",
    "\n",
    "# # Store ID column in another df as it will be dropped before appending\n",
    "# sales_index = sales_test['ID']\n",
    "\n",
    "# sales = (sales_train.groupby(['date_block_num','shop_id','item_id'])\n",
    "#                  .agg({'item_cnt_day': 'sum', 'item_price':'mean' })\n",
    "#                  .rename(columns = {'item_cnt_day':'item_cnt_month'})\n",
    "#                  .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['revenue'] = sales['item_price'] * sales['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_sales_last_month = sales.loc[sales.date_block_num == 33].drop(['date_block_num'], axis=1)\n",
    "\n",
    "# sales_test['date_block_num'] = 34\n",
    "# sales_test = sales_test.merge(item_sales_last_month, on=['shop_id', 'item_id'], how='left').fillna(0)\n",
    "# sales_test.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# sales = sales.append(sales_test, ignore_index=True, sort=False)\n",
    "# print(sales.shape)\n",
    "# sales.tail().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item name [category feature] (additional feature)¶\n",
    "\n",
    "we can split it, and \"one hot encode it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ugly code to show the idea\n",
    "# from collections import Counter\n",
    "# from operator import itemgetter\n",
    "# # If split by '['\n",
    "# items['name_1'], items['name_2'] = items['item_name'].str.split('[', 1).str\n",
    "# # if split by '('\n",
    "# items['name_1'], items['name_3'] = items['item_name'].str.split('(', 1).str\n",
    "\n",
    "# items['name_2'] = items['name_2'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ').str.lower()\n",
    "# items['name_3'] = items['name_3'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ').str.lower()\n",
    "# items = items.fillna('0')\n",
    "\n",
    "# # Dataframe of feature and their count if above 200\n",
    "# result_1 = Counter(' '.join(items['name_2'].values.tolist()).split(' ')).items()\n",
    "# # itemgetter takes keys of dictionaries and converts them into tuples\n",
    "# result_1 = sorted(result_1, key=itemgetter(1))\n",
    "# result_1 = pd.DataFrame(result_1, columns=['feature', 'count'])\n",
    "# result_1 = result_1[(result_1['feature'].str.len() > 1) & (result_1['count'] > 200)]\n",
    "\n",
    "# result_2 = Counter(' '.join(items['name_3'].values.tolist()).split(\" \")).items()\n",
    "# result_2 = sorted(result_2, key=itemgetter(1))\n",
    "# result_2 = pd.DataFrame(result_2, columns=['feature', 'count'])\n",
    "# result_2 = result_2[(result_2['feature'].str.len() > 1) & (result_2['count'] > 200)]\n",
    "\n",
    "# result = pd.concat([result_1, result_2])\n",
    "# result = result.drop_duplicates(subset=['feature'])\n",
    "\n",
    "# #print('Most common aditional features:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shops/Cats/Items preprocessing\n",
    "Observations:\n",
    "\n",
    "* Each shop_name starts with the city name.\n",
    "* Each category contains type and subtype in its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "shops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "#shops\n",
    "shop_city = shops[['shop_id','city_code']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "category['split'] = category['item_category_name'].str.split('-')\n",
    "category['type'] = category['split'].map(lambda x: x[0].strip())\n",
    "category['type_code'] = LabelEncoder().fit_transform(category['type'])\n",
    "\n",
    "category['subtype'] = category['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "category['subtype_code'] = LabelEncoder().fit_transform(category['subtype'])\n",
    "category = category[['item_category_id','type_code', 'subtype_code']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if subtype is nan then type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "    # Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int16)\n",
    "\n",
    "grid['date_block_num'] = grid['date_block_num'].astype(np.int8)\n",
    "grid['shop_id'] = grid['shop_id'].astype(np.int8)\n",
    "grid['item_id'] = grid['item_id'].astype(np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10913850, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = (sales.groupby(['date_block_num','shop_id','item_id'])\n",
    "                 .agg({'item_cnt_day': 'sum', 'item_price':'mean' })\n",
    "                 .rename(columns = {'item_cnt_day':'item_cnt_month'})\n",
    "                 .reset_index())\n",
    "\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "all_data['item_cnt_month'] = (all_data['item_cnt_month']\n",
    "                                .fillna(0)\n",
    "                                .clip(0,20) # NB clip target here\n",
    "                                .astype(np.float16))\n",
    "#all_data = all_data.item_cnt_month.clip(0,20)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10913850.0\n",
       "mean            NaN\n",
       "std             0.0\n",
       "min             0.0\n",
       "25%             0.0\n",
       "50%             0.0\n",
       "75%             0.0\n",
       "max            20.0\n",
       "Name: item_cnt_month, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.item_cnt_month.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128050, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_test['date_block_num'] = 34\n",
    "sales_test['date_block_num'] = sales_test['date_block_num'].astype(np.int8)\n",
    "sales_test['shop_id'] = sales_test['shop_id'].astype(np.int8)\n",
    "sales_test['item_id'] = sales_test['item_id'].astype(np.int16)\n",
    "\n",
    "all_data = (pd.concat([all_data, sales_test], ignore_index=True, sort=False, \n",
    "                      keys=['date_block_num','shop_id','item_id']).fillna(0))\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['revenue'] = all_data['item_price'] * all_data['item_cnt_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(all_data, shops, on=['shop_id'], how='left')\n",
    "all_data = pd.merge(all_data, items, on=['item_id'], how='left')\n",
    "all_data = pd.merge(all_data, category, on=['item_category_id'], how='left')\n",
    "all_data['city_code'] = all_data['city_code'].astype(np.int8)\n",
    "all_data['item_category_id'] = all_data['item_category_id'].astype(np.int8)\n",
    "all_data['type_code'] = all_data['type_code'].astype(np.int8)\n",
    "all_data['subtype_code'] = all_data['subtype_code'].astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(['shop_name','city','item_name','ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11128040</th>\n",
       "      <th>11128041</th>\n",
       "      <th>11128042</th>\n",
       "      <th>11128043</th>\n",
       "      <th>11128044</th>\n",
       "      <th>11128045</th>\n",
       "      <th>11128046</th>\n",
       "      <th>11128047</th>\n",
       "      <th>11128048</th>\n",
       "      <th>11128049</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shop_id</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <td>3280.0</td>\n",
       "      <td>4393.0</td>\n",
       "      <td>4352.0</td>\n",
       "      <td>18049.0</td>\n",
       "      <td>18027.0</td>\n",
       "      <td>18454.0</td>\n",
       "      <td>16188.0</td>\n",
       "      <td>15757.0</td>\n",
       "      <td>19648.0</td>\n",
       "      <td>969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_block_num</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_cnt_month</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_price</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>214190.0</td>\n",
       "      <td>214191.0</td>\n",
       "      <td>214192.0</td>\n",
       "      <td>214193.0</td>\n",
       "      <td>214194.0</td>\n",
       "      <td>214195.0</td>\n",
       "      <td>214196.0</td>\n",
       "      <td>214197.0</td>\n",
       "      <td>214198.0</td>\n",
       "      <td>214199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_code</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id</th>\n",
       "      <td>55.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_code</th>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subtype_code</th>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  11128040  11128041  11128042  11128043  11128044  11128045  \\\n",
       "shop_id               45.0      45.0      45.0      45.0      45.0      45.0   \n",
       "item_id             3280.0    4393.0    4352.0   18049.0   18027.0   18454.0   \n",
       "date_block_num        34.0      34.0      34.0      34.0      34.0      34.0   \n",
       "item_cnt_month         0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "item_price             0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "ID                214190.0  214191.0  214192.0  214193.0  214194.0  214195.0   \n",
       "revenue                0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "city_code             20.0      20.0      20.0      20.0      20.0      20.0   \n",
       "item_category_id      55.0      22.0      22.0      70.0      70.0      55.0   \n",
       "type_code             13.0       5.0       5.0      14.0      14.0      13.0   \n",
       "subtype_code           2.0      14.0      14.0      57.0      57.0       2.0   \n",
       "\n",
       "                  11128046  11128047  11128048  11128049  \n",
       "shop_id               45.0      45.0      45.0      45.0  \n",
       "item_id            16188.0   15757.0   19648.0     969.0  \n",
       "date_block_num        34.0      34.0      34.0      34.0  \n",
       "item_cnt_month         0.0       0.0       0.0       0.0  \n",
       "item_price             0.0       0.0       0.0       0.0  \n",
       "ID                214196.0  214197.0  214198.0  214199.0  \n",
       "revenue                0.0       0.0       0.0       0.0  \n",
       "city_code             20.0      20.0      20.0      20.0  \n",
       "item_category_id      64.0      55.0      40.0      37.0  \n",
       "type_code             14.0      13.0      11.0      11.0  \n",
       "subtype_code          42.0       2.0       4.0       1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.tail(10).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.70s/it]\n"
     ]
    }
   ],
   "source": [
    "all_data = lag_feature(all_data, [1,2], 'item_cnt_month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.87s/it]\n"
     ]
    }
   ],
   "source": [
    "gb = (all_data.groupby(['date_block_num'])\n",
    "                 .agg({'item_cnt_month': 'mean'})\n",
    "                 .rename(columns = {'item_cnt_month':'date_avg_item_cnt'})\n",
    "                 .reset_index())\n",
    "all_data = pd.merge(all_data, gb, how='left', on='date_block_num')\n",
    "all_data['date_avg_item_cnt'] = all_data['date_avg_item_cnt'].astype(np.float16)\n",
    "all_data = lag_feature(all_data, [1], 'date_avg_item_cnt')\n",
    "all_data.drop('date_avg_item_cnt', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:23<00:00, 11.89s/it]\n"
     ]
    }
   ],
   "source": [
    "gb = (all_data.groupby(['date_block_num', 'item_id'])\n",
    "                 .agg({'item_cnt_month': 'mean'})\n",
    "                 .rename(columns = {'item_cnt_month':'date_item_avg_item_cnt'})\n",
    "                 .reset_index())\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['date_block_num', 'item_id'])\n",
    "all_data['date_item_avg_item_cnt'] = all_data['date_item_avg_item_cnt'].astype(np.float16)\n",
    "all_data = lag_feature(all_data, [1,2], 'date_item_avg_item_cnt')\n",
    "all_data.drop('date_item_avg_item_cnt', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.72s/it]\n"
     ]
    }
   ],
   "source": [
    "gb = (all_data.groupby(['date_block_num', 'shop_id'])\n",
    "                 .agg({'item_cnt_month': 'mean'})\n",
    "                 .rename(columns = {'item_cnt_month':'date_shop_avg_item_cnt'})\n",
    "                 .reset_index())\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['date_block_num', 'shop_id'])\n",
    "all_data['date_shop_avg_item_cnt'] = all_data['date_shop_avg_item_cnt'].astype(np.float16)\n",
    "all_data = lag_feature(all_data, [1], 'date_shop_avg_item_cnt')\n",
    "all_data.drop('date_shop_avg_item_cnt', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.09s/it]\n"
     ]
    }
   ],
   "source": [
    "gb = (all_data.groupby(['date_block_num', 'item_category_id'])\n",
    "                 .agg({'item_cnt_month': 'mean'})\n",
    "                 .rename(columns = {'item_cnt_month':'date_cat_avg_item_cnt'})\n",
    "                 .reset_index())\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['date_block_num', 'item_category_id'])\n",
    "all_data['date_cat_avg_item_cnt'] = all_data['date_cat_avg_item_cnt'].astype(np.float16)\n",
    "all_data = lag_feature(all_data, [1], 'date_cat_avg_item_cnt')\n",
    "all_data.drop('date_cat_avg_item_cnt', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.51s/it]\n"
     ]
    }
   ],
   "source": [
    "gb = (all_data.groupby(['date_block_num','shop_id','item_category_id'])\n",
    "                 .agg({'item_cnt_month': 'mean'})\n",
    "                 .rename(columns = {'item_cnt_month':'date_shop_cat_avg_item_cnt'})\n",
    "                 .reset_index())\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['date_block_num','shop_id','item_category_id'])\n",
    "all_data['date_shop_cat_avg_item_cnt'] = all_data['date_shop_cat_avg_item_cnt'].astype(np.float16)\n",
    "all_data = lag_feature(all_data, [1], 'date_shop_cat_avg_item_cnt')\n",
    "all_data.drop('date_shop_cat_avg_item_cnt', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.93s/it]\n"
     ]
    }
   ],
   "source": [
    "gb = (all_data.groupby(['date_block_num','shop_id','type_code'])\n",
    "                 .agg({'item_cnt_month': 'mean'})\n",
    "                 .rename(columns = {'item_cnt_month':'date_shop_type_avg_item_cnt'})\n",
    "                 .reset_index())\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['date_block_num','shop_id','type_code'])\n",
    "all_data['date_shop_type_avg_item_cnt'] = all_data['date_shop_type_avg_item_cnt'].astype(np.float16)\n",
    "all_data = lag_feature(all_data, [1], 'date_shop_type_avg_item_cnt')\n",
    "all_data.drop('date_shop_type_avg_item_cnt', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:14<00:00, 14.19s/it]\n"
     ]
    }
   ],
   "source": [
    "gb = (all_data.groupby(['date_block_num','shop_id','subtype_code'])\n",
    "                 .agg({'item_cnt_month': 'mean'})\n",
    "                 .rename(columns = {'item_cnt_month':'date_shop_subtype_avg_item_cnt'})\n",
    "                 .reset_index())\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['date_block_num','shop_id','subtype_code'])\n",
    "all_data['date_shop_subtype_avg_item_cnt'] = all_data['date_shop_subtype_avg_item_cnt'].astype(np.float16)\n",
    "all_data = lag_feature(all_data, [1], 'date_shop_subtype_avg_item_cnt')\n",
    "all_data.drop('date_shop_subtype_avg_item_cnt', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales.head().T\n",
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = sales.groupby(['item_id']).agg({'item_price': ['mean']})\n",
    "gb.columns = ['item_avg_item_price']\n",
    "gb.reset_index(inplace=True)\n",
    "\n",
    "all_data = pd.merge(all_data, gb, on=['item_id'], how='left')\n",
    "all_data['item_avg_item_price'] = all_data['item_avg_item_price'].fillna(0).astype(np.float16)\n",
    "\n",
    "gb = sales.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\n",
    "gb.columns = ['date_item_avg_item_price']\n",
    "gb.reset_index(inplace=True)\n",
    "\n",
    "all_data = pd.merge(all_data, gb, on=['date_block_num','item_id'], how='left')\n",
    "all_data['date_item_avg_item_price'] = all_data['date_item_avg_item_price'].fillna(0).astype(np.float16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:44<00:00, 14.71s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "lags = [1,2,3]\n",
    "all_data = lag_feature(all_data, lags, 'date_item_avg_item_price')\n",
    "\n",
    "for i in tqdm(lags):\n",
    "    all_data['delta_price_lag_'+str(i)] = \\\n",
    "        (all_data['date_item_avg_item_price_lag_'+str(i)] - \n",
    "             all_data['item_avg_item_price']) / all_data['item_avg_item_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_trend(row):\n",
    "    for i in tqdm(lags):\n",
    "        if row['delta_price_lag_'+str(i)]:\n",
    "            return row['delta_price_lag_'+str(i)]\n",
    "    return 0\n",
    "\n",
    "all_data['delta_price_lag'] = all_data.apply(select_trend, axis=1).fillna(0).astype(np.float16)\n",
    "\n",
    "features_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\n",
    "for i in tqdm(lags):\n",
    "    features_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n",
    "    features_to_drop += ['delta_price_lag_'+str(i)]\n",
    "\n",
    "all_data.drop(features_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = sales.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\n",
    "gb.columns = ['date_shop_revenue']\n",
    "gb.reset_index(inplace=True)\n",
    "\n",
    "all_data = pd.merge(all_data, gb, on=['date_block_num','shop_id'], how='left')\n",
    "all_data['date_shop_revenue'] = all_data['date_shop_revenue'].astype(np.float32)\n",
    "\n",
    "gb = gb.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\n",
    "gb.columns = ['shop_avg_revenue']\n",
    "gb.reset_index(inplace=True)\n",
    "\n",
    "all_data = pd.merge(all_data, gb, on=['shop_id'], how='left')\n",
    "all_data['shop_avg_revenue'] = all_data['shop_avg_revenue'].astype(np.float32)\n",
    "\n",
    "all_data['delta_revenue'] = (all_data['date_shop_revenue'] - all_data['shop_avg_revenue']) / all_data['shop_avg_revenue']\n",
    "all_data['delta_revenue'] = all_data['delta_revenue'].astype(np.float16)\n",
    "\n",
    "all_data = lag_feature(all_data, [1], 'delta_revenue')\n",
    "\n",
    "all_data.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['month'] = all_data['date_block_num'] % 12\n",
    "\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "all_data['days'] = all_data['month'].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "all_data['item_shop_last_sale'] = -1\n",
    "all_data['item_shop_last_sale'] = all_data['item_shop_last_sale'].astype(np.int8)\n",
    "for idx, row in tqdm(all_data.iterrows()):    \n",
    "    key = str(row.item_id)+' '+str(row.shop_id)\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        all_data.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n",
    "        cache[key] = row.date_block_num         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "all_data['item_last_sale'] = -1\n",
    "all_data['item_last_sale'] = all_data['item_last_sale'].astype(np.int8)\n",
    "for idx, row in tqdm(all_data.iterrows()):    \n",
    "    key = row.item_id\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        if row.date_block_num>last_date_block_num:\n",
    "            all_data.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n",
    "            cache[key] = row.date_block_num         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['item_shop_first_sale'] = all_data['date_block_num'] - all_data.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "all_data['item_first_sale'] = all_data['date_block_num'] - all_data.groupby('item_id')['date_block_num'].transform('min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[all_data.date_block_num > 11]\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['shop_id'] = all_data['shop_id'].astype(np.int8)\n",
    "all_data['item_id'] = all_data['item_id'].astype(np.int16)\n",
    "all_data['date_block_num'] = all_data['date_block_num'].astype(np.int8)\n",
    "all_data['item_cnt_month'] = all_data['item_cnt_month'].astype(np.int8)\n",
    "all_data['item_price'] = all_data['item_price'].astype(np.float16)\n",
    "all_data['revenue'] = all_data['revenue'].astype(np.float16)\n",
    "all_data['type_code'] = all_data['type_code'].astype(np.int8)\n",
    "all_data['subtype_code'] = all_data['subtype_code'].astype(np.int8)\n",
    "all_data['city_code'] = all_data['city_code'].astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.rename(columns = {'item_cnt_month':'target'})\n",
    "all_data.tail(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_pickle('all_data.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grid,gb,sales,sales_test,train,shops,items,category,cache\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restart afterr kernal crash\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# import gc\n",
    "# import pickle\n",
    "\n",
    "\n",
    "# all_data = pd.read_pickle('all_data.pkl')\n",
    "# test = pd.read_csv('./final_project_data/test.csv')\n",
    "# sales_index = test['ID']\n",
    "# del test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/ validation/test split\n",
    "\n",
    "34th month data is the test set. 32nd and 33rd data will be taken as validation split and rest as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = all_data['date_block_num']\n",
    "to_drop_cols = ['target', 'item_price']\n",
    "\n",
    "X_train = all_data.loc[(dates <  32)].drop(to_drop_cols, axis=1)\n",
    "X_val = all_data.loc[(dates ==  33) | (dates ==  32)].drop(to_drop_cols, axis=1)\n",
    "X_test =  all_data.loc[dates == 34].drop(to_drop_cols, axis=1)\n",
    "\n",
    "y_train = all_data.loc[(dates <  32), 'target'].values\n",
    "y_val =  all_data.loc[((dates ==  33) | (dates ==  32)), 'target'].values\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "\n",
    "# def root_mean_squared_error(y_true, y_pred):\n",
    "#         return K.sqrt(K.mean(K.square(y_pred - y_true))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model():\n",
    "#     model = keras.Sequential([\n",
    "#         layers.Dense(128, activation='relu',input_shape=[X_train.shape[1]]),\n",
    "#         layers.Dense(128, activation='relu'),\n",
    "#         layers.Dense(64, activation='relu'),\n",
    "#         layers.Dense(32, activation='relu'),\n",
    "#        layers.Dense(1)\n",
    "#       ])\n",
    "\n",
    "# #     optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0)\n",
    "#     optimizer='rmsprop'\n",
    "# #     optimizer='adam'\n",
    "    \n",
    "#     model.compile(loss=root_mean_squared_error,\n",
    "#                 optimizer=optimizer,\n",
    "#                 metrics=['mse',])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 10\n",
    "\n",
    "# history = keras_model.fit(\n",
    "#   X_train, y_train,\n",
    "#   epochs=EPOCHS,\n",
    "#     batch_size=100,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     #callbacks=[callbacks],\n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'val'], loc='upper left')\n",
    "# # plt.ylim(bottom=10, top=12)\n",
    "# # plt.xlim(left=1100, right = 1200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocessing of test data, fit model\n",
    "# preds_test = keras_model.predict(X_test)\n",
    "\n",
    "# # The prediction is of type numpy.ndarray\n",
    "# preds_list = preds_test.tolist()\n",
    "\n",
    "# # Extract the prediction and put it in a list\n",
    "# prediction = []\n",
    "# for item in preds_list:\n",
    "#     prediction.append(item[0])\n",
    "\n",
    "# prediction = np.clip(prediction, 0, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.3,    \n",
    "    seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_model.predict(X_test).clip(0, 20)\n",
    "\n",
    "prediction = (np.clip(preds, 0, 20)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'ID': sales_index,\n",
    "                       'item_cnt_month': prediction})\n",
    "# output.loc[output.item_cnt_month < 0.05, 'item_cnt_month'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_csv('XbgModel.csv', index=False)\n",
    "# output.to_csv('KerasModel.csv', index=False)\n",
    "output.to_csv('XGBModel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.item_cnt_month.describe())\n",
    "print(output.item_cnt_month.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
